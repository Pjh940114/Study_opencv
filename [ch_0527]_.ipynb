{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pjh940114/Study_opencv/blob/main/%5Bch_0527%5D_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bb28f71",
      "metadata": {
        "id": "4bb28f71"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09714379",
      "metadata": {
        "id": "09714379",
        "outputId": "b937356b-c7e0-4c8c-abed-464bda9c009b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of    Unnamed: 0      id tissue class class2      x      y      r\n",
              "0           0  CID000      C  CIRC      N  535.0  475.0  192.0\n",
              "1           1  CID001      A  CIRA      N  433.0  268.0   58.0\n",
              "2           2  CID002      A  CIRA      I    NaN    NaN    NaN\n",
              "3           3  CID003      C  CIRC      B    NaN    NaN    NaN\n",
              "4           4  CID004      F  CIRF      I  488.0  145.0   29.0\n",
              "5           5  CID005      C  CIRC      B  532.0  199.0   21.0>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class2 = pd.read_csv(\"./data/class2.csv\")\n",
        "class2.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5eff091",
      "metadata": {
        "id": "c5eff091",
        "outputId": "28a651c7-cb96-4fe1-b7fc-511acd551e8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 2, 1, 0, 1, 0])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn import preprocessing\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "onehot_encoder = preprocessing.OneHotEncoder()\n",
        "\n",
        "train_x = label_encoder.fit_transform(class2['class2'])\n",
        "train_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9ade740",
      "metadata": {
        "id": "c9ade740",
        "outputId": "8e3c5f8d-48a0-4cc0-db03-44c1b178df68"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'this': 13,\n",
              " 'is': 7,\n",
              " 'last': 8,\n",
              " 'chance': 2,\n",
              " 'and': 0,\n",
              " 'if': 6,\n",
              " 'you': 15,\n",
              " 'do': 3,\n",
              " 'not': 10,\n",
              " 'have': 5,\n",
              " 'will': 14,\n",
              " 'never': 9,\n",
              " 'get': 4,\n",
              " 'any': 1,\n",
              " 'one': 11,\n",
              " 'please': 12}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = [\n",
        "    'This is last chance.',\n",
        "    'and if you do not have this chance.',\n",
        "    'you will never get any chance.',\n",
        "    'will you do get this one?',\n",
        "    'please, get this chance',\n",
        "]\n",
        "vect = CountVectorizer()\n",
        "vect.fit(corpus)\n",
        "vect.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1b1b5a1",
      "metadata": {
        "id": "b1b1b5a1",
        "outputId": "403fa8b3-c3a3-4941-8289-beba28aa6bb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1]], dtype=int64)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vect.transform(['you will never get any chance']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4acd60c2",
      "metadata": {
        "id": "4acd60c2",
        "outputId": "e615c148-7cdb-49f0-97fd-3aa27e33aa15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'last': 6,\n",
              " 'chance': 1,\n",
              " 'if': 5,\n",
              " 'you': 11,\n",
              " 'do': 2,\n",
              " 'not': 8,\n",
              " 'have': 4,\n",
              " 'will': 10,\n",
              " 'never': 7,\n",
              " 'get': 3,\n",
              " 'any': 0,\n",
              " 'one': 9}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vect = CountVectorizer(stop_words = ['and', 'is', 'please', 'this']).fit(corpus)\n",
        "vect.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cd56f3b",
      "metadata": {
        "id": "5cd56f3b",
        "outputId": "e1108845-14ca-4bed-af3f-7027e9644c2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1]], dtype=int64)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vect.transform(['you will never get any chance']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b61dacb6",
      "metadata": {
        "id": "b61dacb6",
        "outputId": "3601da05-3a43-4d17-a2b3-a583a2800839"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "유사도를 위한 3 x 3 행렬을 만들었습니다\n",
            "[[1.       0.224325 0.      ]\n",
            " [0.224325 1.       0.      ]\n",
            " [0.       0.       1.      ]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "doc = ['I like machine learning', 'I love deep learning', 'I run everyday']\n",
        "tfidf_vectorizer = TfidfVectorizer(min_df = 1)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(doc)\n",
        "doc_distance = (tfidf_matrix * tfidf_matrix.T)\n",
        "print(\"유사도를 위한\", str(doc_distance.get_shape()[0]), 'x', str(doc_distance.get_shape()[1]), '행렬을 만들었습니다')\n",
        "print(doc_distance.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af58b9be",
      "metadata": {
        "id": "af58b9be",
        "outputId": "35b892a0-16e6-4104-e7d9-489dca332a45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 2)\t0.4736296010332684\n",
            "  (0, 5)\t0.6227660078332259\n",
            "  (0, 3)\t0.6227660078332259\n",
            "  (1, 0)\t0.6227660078332259\n",
            "  (1, 4)\t0.6227660078332259\n",
            "  (1, 2)\t0.4736296010332684\n",
            "  (2, 1)\t0.7071067811865476\n",
            "  (2, 6)\t0.7071067811865476\n"
          ]
        }
      ],
      "source": [
        "print(tfidf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ea8c99e",
      "metadata": {
        "id": "3ea8c99e",
        "outputId": "500a0a5f-0450-464e-aeec-07cdbcac0652"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (2, 0)\t0.4736296010332684\n",
            "  (5, 0)\t0.6227660078332259\n",
            "  (3, 0)\t0.6227660078332259\n",
            "  (0, 1)\t0.6227660078332259\n",
            "  (4, 1)\t0.6227660078332259\n",
            "  (2, 1)\t0.4736296010332684\n",
            "  (1, 2)\t0.7071067811865476\n",
            "  (6, 2)\t0.7071067811865476\n"
          ]
        }
      ],
      "source": [
        "print(tfidf_matrix.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be3e2482",
      "metadata": {
        "id": "be3e2482",
        "outputId": "784b74f2-cfd5-41d3-d79b-a66da96eedec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 1)\t0.224324998974933\n",
            "  (0, 0)\t1.0000000000000002\n",
            "  (1, 0)\t0.224324998974933\n",
            "  (1, 1)\t1.0000000000000002\n",
            "  (2, 2)\t1.0000000000000002\n"
          ]
        }
      ],
      "source": [
        "print(doc_distance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b28454bd",
      "metadata": {
        "id": "b28454bd",
        "outputId": "f671551a-a83e-4fdd-f37f-89ad87d45c3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4acf7cc6",
      "metadata": {
        "id": "4acf7cc6"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import warnings\n",
        "warnings.filterwarnings(action = 'ignore')\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "sample = open(\"./data/peter.txt\", \"r\", encoding='UTF8')\n",
        "s = sample.read()\n",
        "f = s.replace(\"\\n\", \" \")\n",
        "data = []\n",
        "for i in sent_tokenize(f):\n",
        "    temp = []\n",
        "    for j in word_tokenize(i):\n",
        "        temp.append(j.lower())\n",
        "    data.append(temp)\n",
        "# data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb1da9b9",
      "metadata": {
        "id": "fb1da9b9",
        "outputId": "719d65c2-285a-4a2e-f978-aeb5414d2c23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity between 'peter' 'wendy' - CBOW :  0.074393824\n"
          ]
        }
      ],
      "source": [
        "model1 = gensim.models.Word2Vec(data, min_count = 1,\n",
        "                              vector_size = 100, window = 5)\n",
        "print(\"Cosine similarity between 'peter' \" +\n",
        "                 \"'wendy' - CBOW : \",\n",
        "      model1.wv.similarity('peter', 'wendy'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dda90d5e",
      "metadata": {
        "id": "dda90d5e",
        "outputId": "cc14b9d4-34b8-47a3-94b9-58d6320e4acf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity between 'peter' 'hook' - CBOW :  0.02770985\n"
          ]
        }
      ],
      "source": [
        "print(\"Cosine similarity between 'peter' \" +\n",
        "                 \"'hook' - CBOW : \",\n",
        "      model1.wv.similarity('peter', 'hook'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66d13f3c",
      "metadata": {
        "id": "66d13f3c",
        "outputId": "89bd934a-7bfe-47ea-c199-67089542db7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity between 'peter' wendy' - Skip Gram :  0.40088683\n"
          ]
        }
      ],
      "source": [
        "model2 = gensim.models.Word2Vec(data, min_count = 1, vector_size = 100,\n",
        "                                             window = 5, sg = 1)\n",
        "print(\"Cosine similarity between 'peter' \" +\n",
        "          \"wendy' - Skip Gram : \",\n",
        "    model2.wv.similarity('peter', 'wendy'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2464718",
      "metadata": {
        "id": "d2464718",
        "outputId": "90b4f41d-bb1f-4c93-d8df-0b6ae701d630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity between 'peter' hook' - Skip Gram :  0.52016735\n"
          ]
        }
      ],
      "source": [
        "print(\"Cosine similarity between 'peter' \" +\n",
        "            \"hook' - Skip Gram : \",\n",
        "      model2.wv.similarity('peter', 'hook'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e9d4a1b",
      "metadata": {
        "id": "5e9d4a1b"
      },
      "outputs": [],
      "source": [
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import FastText\n",
        "\n",
        "model = FastText('./data/peter.txt', vector_size=4, window=3, min_count=1, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17c44747",
      "metadata": {
        "id": "17c44747",
        "outputId": "b43c7373-18c8-4e28-82cb-cbaaac6714d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.043825686\n"
          ]
        }
      ],
      "source": [
        "sim_score = model.wv.similarity('peter', 'hook')\n",
        "print(sim_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07b9eabe",
      "metadata": {
        "id": "07b9eabe"
      },
      "outputs": [],
      "source": [
        "#wiki.ko.vec 파일 내려받은 후 실습\n",
        "from __future__ import print_function\n",
        "from gensim.models import KeyedVectors\n",
        "model_kr = KeyedVectors.load_word2vec_format('./data/wiki.ko.vec')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc6b99e2",
      "metadata": {
        "id": "fc6b99e2",
        "outputId": "a648bcc6-7193-41ba-a9ca-80da785c04e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word: 노력함, Similarity: 0.80\n",
            "Word: 노력중, Similarity: 0.75\n",
            "Word: 노력만, Similarity: 0.72\n",
            "Word: 노력과, Similarity: 0.71\n",
            "Word: 노력의, Similarity: 0.69\n",
            "Word: 노력가, Similarity: 0.69\n",
            "Word: 노력이나, Similarity: 0.69\n",
            "Word: 노력없이, Similarity: 0.68\n",
            "Word: 노력맨, Similarity: 0.68\n",
            "Word: 노력보다는, Similarity: 0.68\n"
          ]
        }
      ],
      "source": [
        "find_similar_to = '노력'\n",
        "for similar_word in model_kr.similar_by_word(find_similar_to):\n",
        "    print(\"Word: {0}, Similarity: {1:.2f}\".format(\n",
        "        similar_word[0], similar_word[1]\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "467a26e0",
      "metadata": {
        "id": "467a26e0",
        "outputId": "856ca774-0afb-4ffc-cba9-9abca44bd5f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('초식동물', 0.7804122567176819), ('거대동물', 0.7547270655632019), ('육식동물의', 0.7547166347503662), ('유두동물', 0.753511369228363), ('반추동물', 0.7470757961273193), ('독동물', 0.7466291785240173), ('육상동물', 0.746031641960144), ('유즐동물', 0.7450903654098511), ('극피동물', 0.7449344396591187), ('복모동물', 0.742434561252594)]\n"
          ]
        }
      ],
      "source": [
        "similarities = model_kr.most_similar(positive=['동물', '육식동물'], negative=['사람'])\n",
        "print(similarities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea8896a",
      "metadata": {
        "id": "5ea8896a",
        "outputId": "0483ef44-9268-4fb5-c18d-332485af0476"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(400000, 100)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "%matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "from sklearn.decomposition import PCA\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "glove_file = './data/glove.6B/glove.6B.100d.txt'\n",
        "word2vec_glove_file = get_tmpfile(\"glove.6B.100d.word2vec.txt\")\n",
        "glove2word2vec(glove_file, word2vec_glove_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2bb1e8a",
      "metadata": {
        "id": "f2bb1e8a",
        "outputId": "e51932c4-fefd-4c53-e9ea-2c1c18eed742"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('legislation', 0.8072139620780945),\n",
              " ('proposal', 0.730686366558075),\n",
              " ('senate', 0.7142541408538818),\n",
              " ('bills', 0.704440176486969),\n",
              " ('measure', 0.6958035230636597),\n",
              " ('passed', 0.690624475479126),\n",
              " ('amendment', 0.6846879720687866),\n",
              " ('provision', 0.6845567226409912),\n",
              " ('plan', 0.6816462874412537),\n",
              " ('clinton', 0.6663140058517456)]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = KeyedVectors.load_word2vec_format(word2vec_glove_file)\n",
        "model.most_similar('bill')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14e2612a",
      "metadata": {
        "id": "14e2612a",
        "outputId": "890b5262-7e1c-4625-86e1-d699d03d17c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('peach', 0.688809871673584),\n",
              " ('mango', 0.683819055557251),\n",
              " ('plum', 0.6684104204177856),\n",
              " ('berry', 0.6590359210968018),\n",
              " ('grove', 0.658155083656311),\n",
              " ('blossom', 0.6503506302833557),\n",
              " ('raspberry', 0.6477391719818115),\n",
              " ('strawberry', 0.6442098021507263),\n",
              " ('pine', 0.6390928626060486),\n",
              " ('almond', 0.6379212737083435)]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.most_similar('cherry')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "840d3e2e",
      "metadata": {
        "id": "840d3e2e",
        "outputId": "2d7d54ba-ff6f-4b18-8799-3b4831aa623f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('kazushige', 0.48343509435653687),\n",
              " ('askerov', 0.4778185784816742),\n",
              " ('lakpa', 0.46915265917778015),\n",
              " ('ex-gay', 0.4571332633495331),\n",
              " ('tadayoshi', 0.4522107243537903),\n",
              " ('turani', 0.44810065627098083),\n",
              " ('saglam', 0.4469599425792694),\n",
              " ('aijun', 0.4435270130634308),\n",
              " ('adjustors', 0.44235292077064514),\n",
              " ('nyum', 0.4423118233680725)]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.most_similar(negative=['cherry'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3faa446",
      "metadata": {
        "id": "c3faa446",
        "outputId": "7c720a0d-6e83-46a0-f474-a1f0a308344c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "queen: 0.7699\n"
          ]
        }
      ],
      "source": [
        "result = model.most_similar(positive=['woman', 'king'], negative=['man'])\n",
        "print(\"{}: {:.4f}\".format(*result[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93a02bec",
      "metadata": {
        "id": "93a02bec",
        "outputId": "40dd434e-f74b-40a5-b80b-17a1d419c39b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'champagne'"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def analogy(x1, x2, y1):\n",
        "    result = model.most_similar(positive=[y1, x2], negative=[x1])\n",
        "    return result[0][0]\n",
        "analogy('australia', 'beer', 'france')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1361a3f",
      "metadata": {
        "id": "b1361a3f",
        "outputId": "9fddb657-cedc-4514-d3d4-55204fe5852a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'longest'"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "analogy('tall', 'tallest', 'long')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbb0fb2d",
      "metadata": {
        "id": "bbb0fb2d",
        "outputId": "01039fac-9802-4528-90d4-41103ab48d8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cereal\n"
          ]
        }
      ],
      "source": [
        "print(model.doesnt_match(\"breakfast cereal dinner lunch\".split())) #------ 유사도가 가장 낮은 단어를 반환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81e3f599",
      "metadata": {
        "id": "81e3f599"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "[ch_0527]_.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}